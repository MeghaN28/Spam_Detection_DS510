{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkWb2HU4a9Ek"
      },
      "source": [
        "# 1. Data Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RNMDK9qkbdhS"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lhLtyupwblCv"
      },
      "outputs": [],
      "source": [
        "# Load the dataset and we use encoding='latin-1' because to avoid UnicodeDecodeError\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83e60052"
      },
      "source": [
        "Now that the data is loaded, let's take a look at the first few rows to make sure everything is in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GeLHFaztcwn0",
        "outputId": "7372106c-af70-4cff-b7cf-429aeb3d73bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the top 5 rows\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9tNxtH0c33K",
        "outputId": "95090e10-2d1f-46c1-961c-dfb77a287595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5572, 5)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check the size of the dataset (number of rows, number of columns)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASzCu1AFdCet"
      },
      "source": [
        "# 2. Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFm2Lh9wdICq",
        "outputId": "1ead3b7e-ff80-418d-d807-98517bc55a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v1          5572 non-null   object\n",
            " 1   v2          5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.8+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0DnJ2VfbgTjQ"
      },
      "outputs": [],
      "source": [
        "# Drop irrelevant columns\n",
        "data = data[['v1', 'v2']]  # v1 = label, v2 = message\n",
        "\n",
        "# Rename columns for clarity\n",
        "data.columns = ['Label', 'Message']\n",
        "\n",
        "# Check and remove null values\n",
        "data.isnull().sum()\n",
        "data = data.dropna()\n",
        "\n",
        "# Remove duplicates\n",
        "data = data.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "akBe90nKhiEX",
        "outputId": "102d4f67-ddaa-402b-ad23-dff3547ce8c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES8ZopVehpoS",
        "outputId": "13eaaa22-4460-4685-a3d7-43265a07a045"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5169, 2)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bObgB4JFh0nG"
      },
      "source": [
        "# 3. Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "FLGz4AMchyer",
        "outputId": "2ef21d9e-6b0f-48bb-fdf7-20ae56e13784"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "ham     4516\n",
              "spam     653\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count labels\n",
        "data['Label'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c1EWVI8Y8kw-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/meghanarendrasimha/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Create new features\n",
        "\n",
        "# Create a new column 'num_characters' to store the total number of characters in each message\n",
        "# The len() function returns the number of characters in the string\n",
        "data['num_characters'] = data['Message'].apply(len)\n",
        "\n",
        "# Create a new column 'num_words' to store the total number of words in each message\n",
        "# We use split() to divide the message into a list of words, and then count the length of that list\n",
        "data['num_words'] = data['Message'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Create a new column 'num_sentences' to store the number of sentences in each message\n",
        "# nltk.sent_tokenize() splits the message into sentences using NLP rules\n",
        "# Then we count the number of sentences using len()\n",
        "import nltk\n",
        "nltk.download('punkt')  # Download punkt tokenizer once\n",
        "\n",
        "#data['num_sentences'] = data['Message'].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
        "\n",
        "data['num_sentences'] = data['Message'].apply(lambda x: len(nltk.sent_tokenize(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3TbWbJoO92vS",
        "outputId": "30b193ce-dafc-4c7e-be0b-a899edb288e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>num_characters</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message  num_characters  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...             111   \n",
              "1   ham                      Ok lar... Joking wif u oni...              29   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
              "3   ham  U dun say so early hor... U c already then say...              49   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...              61   \n",
              "\n",
              "   num_words  num_sentences  \n",
              "0         20              2  \n",
              "1          6              2  \n",
              "2         28              2  \n",
              "3         11              1  \n",
              "4         13              1  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTH2EGde-c2V"
      },
      "source": [
        "# 4.Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DH_xxgng-gWg"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords # to remove common words\n",
        "from nltk.stem.porter import PorterStemmer  # for stemming: reducing words to their base form\n",
        "import string # for removing punctuation marks\n",
        "\n",
        "# Initialize the stemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "#function to perform all the preprocessing steps on text data\n",
        "def transform_text(text):\n",
        "    text = text.lower()                            # convert to lowercase\n",
        "    text = nltk.word_tokenize(text)                # Split the text  into words\n",
        "    text = [word for word in text if word.isalnum()]  # remove special characters\n",
        "    text = [word for word in text if word not in stopwords.words('english') and word not in string.punctuation]  # remove stopwords and punctuation\n",
        "    text = [ps.stem(word) for word in text]        # stemming\n",
        "    return \" \".join(text)                          # Join the cleaned words back into a single string\n",
        "\n",
        "# Apply to all messages\n",
        "data['transformed_message'] = data['Message'].apply(transform_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Xh0AQh-j_-36",
        "outputId": "8b3d15ea-0ad7-4cb7-cb49-3cd9a6b23eee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Message</th>\n",
              "      <th>num_characters</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sentences</th>\n",
              "      <th>transformed_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>go jurong point crazi avail bugi n great world...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>u dun say earli hor u c alreadi say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>nah think goe usf live around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            Message  num_characters  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...             111   \n",
              "1   ham                      Ok lar... Joking wif u oni...              29   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
              "3   ham  U dun say so early hor... U c already then say...              49   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...              61   \n",
              "\n",
              "   num_words  num_sentences                                transformed_message  \n",
              "0         20              2  go jurong point crazi avail bugi n great world...  \n",
              "1          6              2                              ok lar joke wif u oni  \n",
              "2         28              2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
              "3         11              1                u dun say earli hor u c alreadi say  \n",
              "4         13              1               nah think goe usf live around though  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "64PCXFFLEk96"
      },
      "outputs": [],
      "source": [
        "# Import two text vectorization tools from scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Count Vectorizer: Simple bag-of-words approach\n",
        "# Create an instance of CountVectorizer\n",
        "# This will convert each message into a vector of word counts\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# Apply CountVectorizer on the preprocessed text column\n",
        "# fit_transform() does two things:\n",
        "#   - Builds a vocabulary of all words in the corpus\n",
        "#   - Transforms each message into a numeric array based on word counts\n",
        "X_bow = cv.fit_transform(data['transformed_message']).toarray()\n",
        "\n",
        "\n",
        "# TF-IDF Vectorizer: Better for weighting important words\n",
        "# Create a TfidfVectorizer instance\n",
        "# max_features=3000 limits the number of unique words to 3000\n",
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "\n",
        "# Apply TF-IDF on the same preprocessed text\n",
        "# This method gives higher weight to important, rare words and lower weight to frequent ones\n",
        "X = tfidf.fit_transform(data['transformed_message']).toarray()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Naive Bayes Spam Detection Model: Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy: 0.9729\n",
            "\n",
            "Confusion Matrix:\n",
            " [[888   1]\n",
            " [ 27 118]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       889\n",
            "           1       0.99      0.81      0.89       145\n",
            "\n",
            "    accuracy                           0.97      1034\n",
            "   macro avg       0.98      0.91      0.94      1034\n",
            "weighted avg       0.97      0.97      0.97      1034\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/meghanarendrasimha/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/meghanarendrasimha/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/meghanarendrasimha/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/meghanarendrasimha/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/meghanarendrasimha/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/meghanarendrasimha/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        }
      ],
      "source": [
        "# Import functions\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Prepare labels\n",
        "y = data['Label'].map({'ham': 0, 'spam': 1}).values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
